{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "openai.api_key = apikey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reusable Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _openai():\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(image_url, promt):\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": promt\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    return _openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(image_url):\n",
    "    promt = \"\"\"\n",
    "        Identify a social situation observable in this picture. \n",
    "        Please respond with a description of the social situation, \n",
    "        he people involved, including their activities and what they\n",
    "        look like. Format your response as a JSON object. Besides \n",
    "        the general descriptions of the social situation, the \n",
    "        resulting JSON object should contain an attribute named\n",
    "        persons containing a list of person object. Make sure a\n",
    "        that every person object not only contains information \n",
    "        about their activity, but also everything observable that \n",
    "        can be used to recognise the same person in another picture.\n",
    "    \"\"\"\n",
    "    return request(image_url, promt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(image_url, person_description):\n",
    "    promt = f\"\"\"\n",
    "        Analyse this picture and decide if you can detect a person that corresponds\n",
    "        to the following description: {person_description}. If the person is present, \n",
    "        provide additional details about their activity in this picture.\n",
    "    \"\"\"\n",
    "    return request(image_url, promt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"description\": \"A group of five people are socializing near a fence with a graffiti-covered train in the background. The individuals appear to be enjoying each other\\'s company, talking and generally hanging out together. They are relaxed and casually dressed.\",\\n  \"persons\": [\\n    {\\n      \"activity\": \"standing and talking\",\\n      \"description\": \"A person leaning against the fence, wearing a light blue denim jacket, black pants, and white sneakers.\",\\n      \"visible_features\": {\\n        \"clothing\": {\\n          \"top\": \"light blue denim jacket\",\\n          \"bottom\": \"black pants\",\\n          \"shoes\": \"white sneakers\"\\n        },\\n        \"stance\": \"standing and leaning against the fence\"\\n      }\\n    },\\n    {\\n      \"activity\": \"sitting and listening\",\\n      \"description\": \"A person sitting on the curb, wearing a brown jacket, blue jeans, and white shoes.\",\\n      \"visible_features\": {\\n        \"clothing\": {\\n          \"top\": \"brown jacket\",\\n          \"bottom\": \"blue jeans\",\\n          \"shoes\": \"white shoes\"\\n        },\\n        \"stance\": \"sitting on the curb\"\\n      }\\n    },\\n    {\\n      \"activity\": \"standing and talking\",\\n      \"description\": \"A person standing with a navy and green sweater with a pink chevron, light blue jeans, and white sneakers.\",\\n      \"visible_features\": {\\n        \"clothing\": {\\n          \"top\": \"navy', role='assistant', function_call=None, tool_calls=None))\n",
      "\n",
      "{\n",
      "  \"description\": \"A group of five people are socializing near a fence with a graffiti-covered train in the background. The individuals appear to be enjoying each other's company, talking and generally hanging out together. They are relaxed and casually dressed.\",\n",
      "  \"persons\": [\n",
      "    {\n",
      "      \"activity\": \"standing and talking\",\n",
      "      \"description\": \"A person leaning against the fence, wearing a light blue denim jacket, black pants, and white sneakers.\",\n",
      "      \"visible_features\": {\n",
      "        \"clothing\": {\n",
      "          \"top\": \"light blue denim jacket\",\n",
      "          \"bottom\": \"black pants\",\n",
      "          \"shoes\": \"white sneakers\"\n",
      "        },\n",
      "        \"stance\": \"standing and leaning against the fence\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"activity\": \"sitting and listening\",\n",
      "      \"description\": \"A person sitting on the curb, wearing a brown jacket, blue jeans, and white shoes.\",\n",
      "      \"visible_features\": {\n",
      "        \"clothing\": {\n",
      "          \"top\": \"brown jacket\",\n",
      "          \"bottom\": \"blue jeans\",\n",
      "          \"shoes\": \"white shoes\"\n",
      "        },\n",
      "        \"stance\": \"sitting on the curb\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"activity\": \"standing and talking\",\n",
      "      \"description\": \"A person standing with a navy and green sweater with a pink chevron, light blue jeans, and white sneakers.\",\n",
      "      \"visible_features\": {\n",
      "        \"clothing\": {\n",
      "          \"top\": \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not Choice",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m json_content \u001b[38;5;241m=\u001b[39m social_situation_choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m7\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(json_content)\n\u001b[0;32m----> 5\u001b[0m social_situation_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocial_situation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m person_tobe_detected \u001b[38;5;241m=\u001b[39m social_situation_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersons\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m recognition \u001b[38;5;241m=\u001b[39m recognize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://chunntguet.xyz/pics/eliott-reyna-5KrZ3UoDKC4-unsplash.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, person_tobe_detected)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not Choice"
     ]
    }
   ],
   "source": [
    "social_situation_choice = extract(\"https://chunntguet.xyz/pics/eliott-reyna-axTm0ee3YP4-unsplash.jpg\")\n",
    "json_content = social_situation_choice.message.content[7:-4]\n",
    "print(json_content)\n",
    "person_tobe_detected = social_situation_dict[\"persons\"][0]\n",
    "recognition = recognize(\"https://chunntguet.xyz/pics/eliott-reyna-5KrZ3UoDKC4-unsplash.jpg\", person_tobe_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"description\": \"A group of five friends are hanging out near a fence with a graffiti-laden train in the background. The group consists of four people standing and one person sitting on a concrete ledge. They appear to be talking and enjoying each other\\'s company.\",\\n  \"persons\": [\\n    {\\n      \"id\": 1,\\n      \"activity\": \"Standing with one foot on the ledge, leaning against a fence.\",\\n      \"observable_features\": {\\n        \"clothing\": \"Light gray hoodie, denim jacket, black pants, white sneakers.\",\\n        \"pose\": \"Leaning against the fence with one foot on the ledge.\",\\n        \"hair\": \"Short dark hair.\"\\n      }\\n    },\\n    {\\n      \"id\": 2,\\n      \"activity\": \"Sitting on the ledge.\",\\n      \"observable_features\": {\\n        \"clothing\": \"Brown jacket, blue jeans, white socks, white sneakers.\",\\n        \"pose\": \"Sitting with hands clasped in front.\",\\n        \"hair\": \"Short dark hair.\"\\n      }\\n    },\\n    {\\n      \"id\": 3,\\n      \"activity\": \"Standing and talking.\",\\n      \"observable_features\": {\\n        \"clothing\": \"Black and white plaid shirt over a dark shirt, black jeans, black shoes.\",\\n        \"pose\": \"Standing with arms crossed.\",\\n        \"hair\": \"Short dark hair with facial hair.\"\\n      }\\n    },\\n    {\\n      \"id\": 4,\\n', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_situation_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image depicts a serene landscape with a wooden boardwalk extending through an open grassy field. The field is covered with lush green grass and some scattered bushes. In the background, there are more dense areas of trees and vegetation. The sky above is clear with scattered clouds, creating a calm and picturesque scene.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
